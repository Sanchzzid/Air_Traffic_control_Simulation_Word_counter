{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2164ab97",
   "metadata": {},
   "source": [
    "# PROJECT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44092e84",
   "metadata": {},
   "source": [
    "## AIR TRAFFIC CONTROL SIMULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80a85fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flight:\n",
    "    def _init_(self, flight_number, emergency=False):\n",
    "        self.flight_number = flight_number\n",
    "        self.emergency = emergency\n",
    "\n",
    "    def _str_(self):\n",
    "        return f\"Flight {self.flight_number} (Emergency: {self.emergency})\"\n",
    "    class Flight:\n",
    "        def _init_(self, flight_number, emergency=False):\n",
    "            self.flight_number = flight_number\n",
    "            self.emergency = emergency\n",
    "\n",
    "    def _str_(self):\n",
    "        return f\"Flight {self.flight_number} (Emergency: {self.emergency})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31878513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e87a8070",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Flight() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-3558c438efe1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create flights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mflight1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ABC123\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memergency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mflight2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"XYZ789\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memergency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mflight3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DEF456\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memergency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mflight4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GHI789\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memergency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Flight() takes no arguments"
     ]
    }
   ],
   "source": [
    "# Create flights\n",
    "flight1 = Flight(\"ABC123\", emergency=True)\n",
    "flight2 = Flight(\"XYZ789\", emergency=False)\n",
    "flight3 = Flight(\"DEF456\", emergency=True)\n",
    "flight4 = Flight(\"GHI789\", emergency=False)\n",
    "\n",
    "# Create landing queue\n",
    "landing_queue = LandingQueue()\n",
    "\n",
    "# Enqueue flights\n",
    "landing_queue.enqueue(flight1)\n",
    "landing_queue.enqueue(flight2)\n",
    "landing_queue.enqueue(flight3)\n",
    "landing_queue.enqueue(flight4)\n",
    "\n",
    "# Prioritize emergencies\n",
    "landing_queue.prioritize_emergencies()\n",
    "\n",
    "# Display queue\n",
    "print(\"Landing Queue:\")\n",
    "landing_queue.display_queue()\n",
    "\n",
    "# Dequeue flights\n",
    "print(\"\\nDequeueing:\")\n",
    "while landing_queue.queue:\n",
    "    flight = landing_queue.dequeue()\n",
    "    print(f\"Dequeued: {flight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a0046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414343f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d8c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a654e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ec322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1482933-510e-4955-8667-ccb4a351f43e",
   "metadata": {},
   "source": [
    "# Project 2: File handling – word counter  \n",
    "Problem: You are tasked with developing a plagiarism detection system for a school. Given a text file containing a student's essay and a set of reference files, you need to determine if any part of the essay is copied from the reference materials. Design a program that reads and compares the essay with the reference files to identify potential plagiarism instances.\n",
    "\n",
    "- Display the frequency of each word in the provided text file.\n",
    "- Learn how to read and process data from text files using file handling.\n",
    "- Practice tokenization of text into words for analysis.\n",
    "- Understand the basics of counting and analyzing data frequencies.\n",
    "- Gain experience in creating a simple text data analysis tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5856ba6-59d9-48e6-beda-737eb77eaf90",
   "metadata": {},
   "source": [
    "Firstly, I will create a list of \"stop words\" that will be dispatched from the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2257974-8174-4d33-b554-77fdf2528d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stop_words = [\n",
    "    \"the\", \"and\", \"of\", \"to\", \"in\", \"for\", \"with\", \"on\", \"by\", \"at\", \"as\", \"an\", \"a\", \"but\", \"or\", \"nor\", \"so\", \"yet\", \n",
    "    \"if\", \"is\", \"was\", \"be\", \"are\", \"am\", \"it\", \"I\", \"you\", \"he\", \"she\", \"we\", \"they\", \"me\", \"him\", \"her\", \"us\", \"them\", \n",
    "    \"my\", \"your\", \"his\", \"its\", \"our\", \"their\", \"mine\", \"yours\", \"hers\", \"ours\", \"theirs\", \"this\", \"that\", \"these\", \n",
    "    \"those\", \"such\", \"some\", \"all\", \"most\", \"many\", \"few\", \"several\", \"both\", \"neither\", \"either\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44a43c21-8105-42fd-b440-79fc653cc049",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_signs = [\n",
    "    \".\", \",\", \"!\", \"?\", \";\", \":\", \"-\", \"'\", \"\\\"\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"<\", \">\", \"/\", \"|\", \"\\\\\",\n",
    "    \"...\", \"--\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"<\", \">\", \"/\", \"|\", \"\\\\\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8554f0d2-bcdf-45c0-929f-8060a104c848",
   "metadata": {},
   "source": [
    "Creation of a function that reads a text file and returns the frecuency of most important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1863701b-34ce-4060-a3e2-d1520a8ca69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(textfile):\n",
    "    # read the file\n",
    "    with open(textfile, 'r') as file:\n",
    "        file_content = file.readlines()\n",
    "    # remove the newline characters\n",
    "    file_content = [i.replace('\\n', '') for i in file_content]\n",
    "    # join all the lines in one long string\n",
    "    file_content = ' '.join(file_content)\n",
    "    # remove punctuation marks\n",
    "    for sign in punctuation_signs:\n",
    "        file_content = file_content.replace(sign, ' ')\n",
    "    # create a list of words\n",
    "    words_list= file_content.split(' ')\n",
    "    # drop the \"stop words\"\n",
    "    final_words_list = []\n",
    "    for word in words_list:\n",
    "        # don't include word if:\n",
    "        # 1. word is stop word\n",
    "        # 2. word is empty string ''\n",
    "        # 3. word is a number or starts with a number\n",
    "        if not word in common_stop_words and word != ''  and not word[0].isnumeric():\n",
    "            final_words_list.append(word.lower())\n",
    "    return final_words_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011da964-0619-4a0f-a96e-f68b46fd0e6c",
   "metadata": {},
   "source": [
    "Function to count the different words found in the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "531de285-5a62-42a6-8fe8-f5c832593069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(word_list):\n",
    "    word_count_dict = {}\n",
    "    for word in word_list:\n",
    "        if word not in word_count_dict.keys():\n",
    "            # if word isn't still in the word count, create count with value = 1\n",
    "            word_count_dict[word] = 1\n",
    "        else:\n",
    "            # if word already belongs to word count, add up 1 to count\n",
    "            word_count_dict[word] += 1\n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7224272-10b2-452d-974b-ff787a900e85",
   "metadata": {},
   "source": [
    "Pretty print the results of the word counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9730aa77-9dd3-4001-87c8-541cb977e58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word:\t\t\tCount:\n",
      "_\t\t\t1\n",
      "d\t\t\t1\n",
      "i\t\t\t1\n",
      "l\t\t\t1\n",
      "o\t\t\t1\n",
      "r\t\t\t1\n",
      "s\t\t\t1\n",
      "t\t\t\t1\n",
      "w\t\t\t1\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_word_count(word_count_dict):\n",
    "    print('Word:\\t\\t\\tCount:')\n",
    "    sorted_words = sorted(word_count_dict.keys())\n",
    "    for word in sorted_words:\n",
    "        print(f'{word}\\t\\t\\t{word_count_dict[word]}')\n",
    "pretty_print_word_count(word_count_dict)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f904bf-e5a8-4a65-ace6-d04d072ab39f",
   "metadata": {},
   "source": [
    "Finally, let's check it with a text file called `oop.txt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e869efb9-c074-4cb7-ae09-5ba0b3594ac5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# word_list = extract_words('oop.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "410cd4a8-b136-40b4-af6d-dcc53fe79103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w': 1, 'o': 1, 'r': 1, 'd': 1, '_': 1, 'l': 1, 'i': 1, 's': 1, 't': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_dict = word_counter('word_list')\n",
    "word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c1d8875-bc11-469c-92e0-b602f854c082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word:\t\t\tCount:\n",
      "a\t\t\t1\n",
      "able\t\t\t1\n",
      "about\t\t\t1\n",
      "abstract\t\t\t1\n",
      "abstraction\t\t\t2\n",
      "across\t\t\t1\n",
      "ada\t\t\t1\n",
      "added\t\t\t2\n",
      "adding\t\t\t1\n",
      "adele\t\t\t1\n",
      "adopt\t\t\t1\n",
      "aed\t\t\t1\n",
      "alan\t\t\t4\n",
      "albeit\t\t\t1\n",
      "algol\t\t\t1\n",
      "allowing\t\t\t1\n",
      "allows\t\t\t1\n",
      "alphard\t\t\t1\n",
      "also\t\t\t5\n",
      "although\t\t\t3\n",
      "an\t\t\t1\n",
      "another\t\t\t1\n",
      "appearance\t\t\t1\n",
      "application\t\t\t1\n",
      "applications\t\t\t1\n",
      "approach\t\t\t1\n",
      "architectures\t\t\t1\n",
      "artificial\t\t\t1\n",
      "association\t\t\t1\n",
      "at\t\t\t1\n",
      "atoms\t\t\t1\n",
      "attempts\t\t\t1\n",
      "attended\t\t\t1\n",
      "attributes\t\t\t1\n",
      "audience\t\t\t1\n",
      "august\t\t\t1\n",
      "authored\t\t\t1\n",
      "available\t\t\t1\n",
      "barbara\t\t\t1\n",
      "based\t\t\t4\n",
      "basic\t\t\t2\n",
      "became\t\t\t2\n",
      "been\t\t\t3\n",
      "beginning\t\t\t1\n",
      "being\t\t\t1\n",
      "benefit\t\t\t1\n",
      "bertrand\t\t\t1\n",
      "between\t\t\t1\n",
      "binding\t\t\t1\n",
      "biological\t\t\t1\n",
      "bjarne\t\t\t1\n",
      "black\t\t\t1\n",
      "boundaries\t\t\t1\n",
      "brad\t\t\t1\n",
      "button\t\t\t2\n",
      "byte\t\t\t1\n",
      "c\t\t\t4\n",
      "c#\t\t\t2\n",
      "c++\t\t\t2\n",
      "called\t\t\t2\n",
      "came\t\t\t1\n",
      "can\t\t\t2\n",
      "cargo\t\t\t1\n",
      "cells\t\t\t1\n",
      "checking\t\t\t1\n",
      "citation\t\t\t2\n",
      "cited\t\t\t1\n",
      "class\t\t\t6\n",
      "classes\t\t\t4\n",
      "closely\t\t\t1\n",
      "clu\t\t\t1\n",
      "co\t\t\t1\n",
      "cobol\t\t\t1\n",
      "cocoa\t\t\t1\n",
      "code\t\t\t1\n",
      "colleagues\t\t\t1\n",
      "commercially\t\t\t1\n",
      "common\t\t\t2\n",
      "communicate\t\t\t1\n",
      "community\t\t\t1\n",
      "compatibility\t\t\t1\n",
      "compatible\t\t\t1\n",
      "competed\t\t\t1\n",
      "compiled\t\t\t1\n",
      "computer\t\t\t2\n",
      "computers\t\t\t1\n",
      "computing\t\t\t1\n",
      "concept\t\t\t2\n",
      "concepts\t\t\t1\n",
      "conference\t\t\t1\n",
      "construction\t\t\t1\n",
      "content\t\t\t1\n",
      "contract\t\t\t1\n",
      "conventional\t\t\t1\n",
      "conversation\t\t\t1\n",
      "could\t\t\t2\n",
      "covered\t\t\t1\n",
      "cox\t\t\t1\n",
      "create\t\t\t1\n",
      "created\t\t\t3\n",
      "creating\t\t\t1\n",
      "cross\t\t\t1\n",
      "dan\t\t\t1\n",
      "data\t\t\t4\n",
      "defined\t\t\t3\n",
      "definition\t\t\t1\n",
      "delphi\t\t\t1\n",
      "described\t\t\t1\n",
      "design\t\t\t5\n",
      "designed\t\t\t3\n",
      "detailed\t\t\t1\n",
      "developed\t\t\t4\n",
      "developers\t\t\t1\n",
      "development\t\t\t2\n",
      "dialect\t\t\t1\n",
      "did\t\t\t1\n",
      "differentiated\t\t\t1\n",
      "direct\t\t\t1\n",
      "direction\t\t\t1\n",
      "dissertation\t\t\t1\n",
      "distinctive\t\t\t1\n",
      "do\t\t\t1\n",
      "does\t\t\t1\n",
      "dominance\t\t\t1\n",
      "dominant\t\t\t1\n",
      "down\t\t\t1\n",
      "driven\t\t\t1\n",
      "dynamic\t\t\t4\n",
      "dynamically\t\t\t2\n",
      "each\t\t\t1\n",
      "earlier\t\t\t1\n",
      "early\t\t\t5\n",
      "edited\t\t\t1\n",
      "efficiently\t\t\t1\n",
      "eiffel\t\t\t4\n",
      "emerged\t\t\t1\n",
      "engineering\t\t\t1\n",
      "enhanced\t\t\t2\n",
      "enough\t\t\t1\n",
      "entire\t\t\t1\n",
      "environment\t\t\t3\n",
      "essential\t\t\t2\n",
      "established\t\t\t1\n",
      "establishment\t\t\t1\n",
      "eth\t\t\t1\n",
      "event\t\t\t1\n",
      "eventually\t\t\t2\n",
      "example\t\t\t2\n",
      "examples\t\t\t1\n",
      "existing\t\t\t1\n",
      "experimentation\t\t\t1\n",
      "extension\t\t\t3\n",
      "extensions\t\t\t1\n",
      "father\t\t\t1\n",
      "features\t\t\t2\n",
      "first\t\t\t5\n",
      "flavors\t\t\t1\n",
      "focus\t\t\t1\n",
      "focused\t\t\t1\n",
      "fortran\t\t\t1\n",
      "found\t\t\t1\n",
      "foxpro\t\t\t1\n",
      "frameworks\t\t\t2\n",
      "from\t\t\t5\n",
      "fully\t\t\t1\n",
      "functional\t\t\t1\n",
      "functions\t\t\t2\n",
      "further\t\t\t1\n",
      "glossary\t\t\t1\n",
      "goldberg\t\t\t2\n",
      "graph\t\t\t1\n",
      "graphical\t\t\t3\n",
      "green\t\t\t1\n",
      "grew\t\t\t1\n",
      "group\t\t\t1\n",
      "gui\t\t\t1\n",
      "had\t\t\t4\n",
      "hardware\t\t\t1\n",
      "has\t\t\t4\n",
      "have\t\t\t2\n",
      "heavily\t\t\t1\n",
      "history\t\t\t1\n",
      "how\t\t\t1\n",
      "iapx\t\t\t1\n",
      "ideas\t\t\t2\n",
      "identified\t\t\t1\n",
      "implementation\t\t\t1\n",
      "implied\t\t\t1\n",
      "important\t\t\t2\n",
      "improve\t\t\t1\n",
      "in\t\t\t10\n",
      "inc\t\t\t1\n",
      "include\t\t\t1\n",
      "included\t\t\t5\n",
      "including\t\t\t1\n",
      "incorporate\t\t\t1\n",
      "index\t\t\t1\n",
      "individual\t\t\t1\n",
      "influence\t\t\t1\n",
      "influenced\t\t\t2\n",
      "ingalls\t\t\t1\n",
      "inheritance\t\t\t5\n",
      "inheritor\t\t\t1\n",
      "initially\t\t\t1\n",
      "instance\t\t\t1\n",
      "instances\t\t\t1\n",
      "integral\t\t\t1\n",
      "integrates\t\t\t1\n",
      "intel\t\t\t1\n",
      "intelligence\t\t\t1\n",
      "interaction\t\t\t1\n",
      "interest\t\t\t1\n",
      "interfaces\t\t\t1\n",
      "internals\t\t\t1\n",
      "interpreted\t\t\t1\n",
      "introduced\t\t\t3\n",
      "introducing\t\t\t2\n",
      "investigating\t\t\t1\n",
      "invoking\t\t\t1\n",
      "involved\t\t\t1\n",
      "issue\t\t\t1\n",
      "it\t\t\t1\n",
      "items\t\t\t1\n",
      "its\t\t\t1\n",
      "itt\t\t\t1\n",
      "ivan\t\t\t1\n",
      "java\t\t\t2\n",
      "kay\t\t\t4\n",
      "key\t\t\t1\n",
      "language\t\t\t13\n",
      "languages\t\t\t8\n",
      "late\t\t\t1\n",
      "later\t\t\t2\n",
      "led\t\t\t2\n",
      "level\t\t\t1\n",
      "library\t\t\t1\n",
      "lifecycle\t\t\t1\n",
      "like\t\t\t1\n",
      "limited\t\t\t1\n",
      "link\t\t\t1\n",
      "linn\t\t\t1\n",
      "liskov\t\t\t1\n",
      "lisp\t\t\t6\n",
      "lists\t\t\t1\n",
      "looks\t\t\t1\n",
      "loops\t\t\t1\n",
      "mac\t\t\t1\n",
      "machine\t\t\t1\n",
      "machinery\t\t\t1\n",
      "made\t\t\t1\n",
      "magazine\t\t\t1\n",
      "mainly\t\t\t1\n",
      "maintainability\t\t\t1\n",
      "master\t\t\t1\n",
      "mechanism\t\t\t1\n",
      "member\t\t\t1\n",
      "memo\t\t\t1\n",
      "memory\t\t\t1\n",
      "mention\t\t\t1\n",
      "messages\t\t\t2\n",
      "messaging\t\t\t3\n",
      "meta\t\t\t1\n",
      "method\t\t\t2\n",
      "methodology\t\t\t1\n",
      "methods\t\t\t1\n",
      "meyer\t\t\t3\n",
      "microsoft\t\t\t1\n",
      "microsystems\t\t\t1\n",
      "mid\t\t\t2\n",
      "mit\t\t\t4\n",
      "mixins\t\t\t1\n",
      "modelling\t\t\t1\n",
      "models\t\t\t1\n",
      "modern\t\t\t1\n",
      "modified\t\t\t1\n",
      "modula\t\t\t1\n",
      "modular\t\t\t1\n",
      "module\t\t\t1\n",
      "more\t\t\t2\n",
      "movement\t\t\t1\n",
      "multiple\t\t\t1\n",
      "needed\t\t\t2\n",
      "net\t\t\t4\n",
      "network\t\t\t1\n",
      "niklaus\t\t\t1\n",
      "nomenclature\t\t\t1\n",
      "not\t\t\t7\n",
      "notation\t\t\t2\n",
      "noted\t\t\t1\n",
      "notion\t\t\t3\n",
      "notions\t\t\t1\n",
      "number\t\t\t2\n",
      "oberon\t\t\t1\n",
      "object\t\t\t28\n",
      "objective\t\t\t2\n",
      "objects\t\t\t4\n",
      "obvious\t\t\t1\n",
      "often\t\t\t1\n",
      "one\t\t\t1\n",
      "only\t\t\t1\n",
      "oo\t\t\t1\n",
      "oop\t\t\t4\n",
      "oopsla\t\t\t1\n",
      "opposite\t\t\t1\n",
      "organised\t\t\t1\n",
      "orientation\t\t\t2\n",
      "oriented\t\t\t19\n",
      "os\t\t\t1\n",
      "other\t\t\t1\n",
      "own\t\t\t1\n",
      "paradigm\t\t\t1\n",
      "parc\t\t\t1\n",
      "parent\t\t\t1\n",
      "part\t\t\t2\n",
      "pascal\t\t\t1\n",
      "people\t\t\t1\n",
      "phd\t\t\t1\n",
      "physical\t\t\t1\n",
      "platform\t\t\t1\n",
      "plexes\t\t\t1\n",
      "popularity\t\t\t3\n",
      "ports\t\t\t1\n",
      "position\t\t\t1\n",
      "prefiguring\t\t\t1\n",
      "previously\t\t\t1\n",
      "primarily\t\t\t1\n",
      "probably\t\t\t1\n",
      "problems\t\t\t1\n",
      "procedural\t\t\t2\n",
      "procedures\t\t\t1\n",
      "processor\t\t\t1\n",
      "produced\t\t\t1\n",
      "programming\t\t\t20\n",
      "properties\t\t\t1\n",
      "protocol\t\t\t1\n",
      "purely\t\t\t1\n",
      "python\t\t\t1\n",
      "quality\t\t\t2\n",
      "recent\t\t\t1\n",
      "recently\t\t\t1\n",
      "refer\t\t\t1\n",
      "rekursiv\t\t\t1\n",
      "related\t\t\t1\n",
      "reliability\t\t\t1\n",
      "rely\t\t\t1\n",
      "report\t\t\t1\n",
      "researchers\t\t\t1\n",
      "rising\t\t\t1\n",
      "ruby\t\t\t1\n",
      "s\t\t\t3\n",
      "science\t\t\t2\n",
      "see\t\t\t1\n",
      "sense\t\t\t1\n",
      "ships\t\t\t1\n",
      "shows\t\t\t1\n",
      "simula\t\t\t5\n",
      "since\t\t\t2\n",
      "sketchpad\t\t\t2\n",
      "small\t\t\t1\n",
      "smalltalk\t\t\t10\n",
      "smart\t\t\t1\n",
      "software\t\t\t5\n",
      "sometimes\t\t\t1\n",
      "specialized\t\t\t1\n",
      "strong\t\t\t1\n",
      "stroustrup\t\t\t1\n",
      "structures\t\t\t1\n",
      "study\t\t\t1\n",
      "subclass\t\t\t2\n",
      "subset\t\t\t1\n",
      "succeeding\t\t\t1\n",
      "successful\t\t\t1\n",
      "sun\t\t\t1\n",
      "support\t\t\t2\n",
      "supporting\t\t\t2\n",
      "sutherland\t\t\t2\n",
      "system\t\t\t2\n",
      "systems\t\t\t1\n",
      "technical\t\t\t1\n",
      "techniques\t\t\t3\n",
      "term\t\t\t1\n",
      "termed\t\t\t1\n",
      "terminology\t\t\t1\n",
      "the\t\t\t2\n",
      "there\t\t\t1\n",
      "these\t\t\t1\n",
      "thesis\t\t\t1\n",
      "thinking\t\t\t1\n",
      "this\t\t\t1\n",
      "thought\t\t\t1\n",
      "through\t\t\t3\n",
      "tiobe\t\t\t1\n",
      "today\t\t\t1\n",
      "took\t\t\t1\n",
      "toolkits\t\t\t1\n",
      "top\t\t\t1\n",
      "topics\t\t\t1\n",
      "two\t\t\t2\n",
      "type\t\t\t3\n",
      "typed\t\t\t1\n",
      "uml\t\t\t1\n",
      "understanding\t\t\t1\n",
      "unexpectedly\t\t\t1\n",
      "upon\t\t\t1\n",
      "use\t\t\t1\n",
      "used\t\t\t4\n",
      "useful\t\t\t1\n",
      "user\t\t\t1\n",
      "using\t\t\t1\n",
      "variables\t\t\t1\n",
      "various\t\t\t2\n",
      "vb\t\t\t2\n",
      "version\t\t\t2\n",
      "versions\t\t\t1\n",
      "very\t\t\t1\n",
      "via\t\t\t2\n",
      "viewpoint\t\t\t1\n",
      "visual\t\t\t2\n",
      "way\t\t\t1\n",
      "well\t\t\t1\n",
      "went\t\t\t2\n",
      "were\t\t\t5\n",
      "what\t\t\t1\n",
      "when\t\t\t1\n",
      "which\t\t\t5\n",
      "while\t\t\t2\n",
      "who\t\t\t2\n",
      "widely\t\t\t1\n",
      "wider\t\t\t1\n",
      "wirth\t\t\t3\n",
      "written\t\t\t1\n",
      "x\t\t\t1\n",
      "xerox\t\t\t1\n",
      "zürich\t\t\t1\n",
      "–\t\t\t1\n"
     ]
    }
   ],
   "source": [
    "pretty_print_word_count(word_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ef31f-2839-4074-ac69-6a440cf482fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
